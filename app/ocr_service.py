# ocr_service.py - Azure App Serviceå¯¾å¿œä¿®æ­£ç‰ˆï¼ˆç¾è¡Œãƒ™ãƒ¼ã‚¹ï¼‰
import os
import re
import json
import tempfile
import uuid
from typing import Dict, Any, Tuple, List, Optional
import logging
from datetime import datetime
from pathlib import Path

import pytesseract
from PIL import Image
from pdf2image import convert_from_path
from sqlalchemy.orm import Session

from app import models
from app.database import SessionLocal  # æ—¢å­˜ã®database.pyã‚’ä½¿ç”¨
from app.config import OCR_TEMP_FOLDER, TESSERACT_CMD, MAX_FILE_SIZE  # ç¾è¡Œconfig.pyã‚’ä½¿ç”¨
from app.ocr_extractors import (
    identify_po_format, 
    extract_format1_data, 
    extract_format2_data, 
    extract_format3_data, 
    extract_generic_data
)

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

# ========== Azureå¯¾å¿œã®æ–°æ©Ÿèƒ½è¿½åŠ  ==========

def setup_tesseract_for_azure():
    """Azureç’°å¢ƒã§ã®Tesseractè¨­å®šï¼ˆæ–°è¦è¿½åŠ ï¼‰"""
    try:
        # Azureç’°å¢ƒåˆ¤å®š
        is_azure = os.getenv("WEBSITE_SITE_NAME") is not None
        
        if is_azure:
            logger.info("ğŸ”§ Azureç’°å¢ƒã§ã®Tesseractè¨­å®šã‚’å®Ÿè¡Œä¸­...")
            
            # è¤‡æ•°ã®ãƒ‘ã‚¹ã‚’è©¦è¡Œ
            tesseract_paths = [
                "/usr/bin/tesseract",
                "/usr/local/bin/tesseract", 
                "/opt/conda/bin/tesseract",
                "tesseract"  # PATHå†…æ¤œç´¢
            ]
            
            for path in tesseract_paths:
                try:
                    pytesseract.pytesseract.tesseract_cmd = path
                    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
                    version = pytesseract.get_tesseract_version()
                    logger.info(f"âœ… Tesseractè¨­å®šæˆåŠŸ: {path} (version: {version})")
                    return True
                except Exception as e:
                    logger.debug(f"âŒ Tesseractãƒ‘ã‚¹å¤±æ•—: {path} - {e}")
                    continue
            
            # å…¨ã¦å¤±æ•—ã—ãŸå ´åˆã®è­¦å‘Š
            logger.warning("âš ï¸ Tesseractãƒã‚¤ãƒŠãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            return False
        else:
            # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã®é€šå¸¸è¨­å®š
            if TESSERACT_CMD and os.path.exists(TESSERACT_CMD):
                pytesseract.pytesseract.tesseract_cmd = TESSERACT_CMD
                logger.info(f"âœ… Tesseractè¨­å®šå®Œäº†: {TESSERACT_CMD}")
                return True
    
    except ImportError:
        logger.error("âŒ pytesseractã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        return False
    except Exception as e:
        logger.error(f"âŒ Tesseractè¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
        return False

def process_document_fallback(file_path: str, ocr_id: int, db: Session):
    """TesseractãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ï¼ˆæ–°è¦è¿½åŠ ï¼‰"""
    try:
        logger.info("ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†: åŸºæœ¬çš„ãªPDFè§£æã‚’å®Ÿè¡Œä¸­...")
        
        # PDFMinerã‚’ä½¿ç”¨ã—ãŸãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
        raw_text = ""
        file_ext = os.path.splitext(file_path)[1].lower()
        
        if file_ext == '.pdf':
            try:
                from pdfminer.high_level import extract_text
                raw_text = extract_text(file_path)
                logger.info("âœ… PDFMinerã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå®Œäº†")
            except Exception as e:
                logger.error(f"âŒ PDFMinerå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                raw_text = f"PDFå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}\n\nOCRæ©Ÿèƒ½ã‚’åˆ©ç”¨ã™ã‚‹ã«ã¯TesseractãŒå¿…è¦ã§ã™ã€‚"
        
        elif file_ext in ['.png', '.jpg', '.jpeg']:
            # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            raw_text = "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®OCRå‡¦ç†ã«ã¯TesseractãŒå¿…è¦ã§ã™ã€‚ç¾åœ¨ã®ç’°å¢ƒã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚"
        
        else:
            raw_text = f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: {file_ext}"
        
        # çµæœã‚’ä¿å­˜
        processed_data = {
            "original_filename": os.path.basename(file_path),
            "text_content": raw_text,
            "processing_method": "fallback_pdfminer",
            "processing_timestamp": datetime.utcnow().isoformat(),
            "warning": "TesseractãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€åˆ¶é™ã•ã‚ŒãŸå‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã—ãŸã€‚"
        }
        
        update_ocr_result(db, ocr_id, raw_text, json.dumps(processed_data), "completed")
        logger.info("âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†å®Œäº†")
        
    except Exception as e:
        logger.error(f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        update_ocr_result(db, ocr_id, "", json.dumps({"error": str(e)}), "failed", str(e))

# ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ã‚¯ãƒ©ã‚¹ï¼ˆAzureå¯¾å¿œä¿®æ­£ç‰ˆï¼‰
class TempFileManager:
    def __init__(self):
        # Azureç’°å¢ƒå¯¾å¿œã®ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªé¸æŠ
        is_azure = os.getenv("WEBSITE_SITE_NAME") is not None
        
        if is_azure:
            # Azureç’°å¢ƒã§ã¯è¤‡æ•°ã®å€™è£œã‹ã‚‰æ›¸ãè¾¼ã¿å¯èƒ½ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’é¸æŠ
            temp_candidates = [
                OCR_TEMP_FOLDER,
                "/tmp/po_uploads", 
                "/home/site/wwwroot/temp",
                tempfile.gettempdir(),
                "/tmp"
            ]
            
            self.temp_dir = None
            for candidate in temp_candidates:
                try:
                    candidate_path = Path(candidate)
                    candidate_path.mkdir(parents=True, exist_ok=True)
                    
                    # æ›¸ãè¾¼ã¿ãƒ†ã‚¹ãƒˆ
                    test_file = candidate_path / "write_test.tmp"
                    test_file.write_text("test")
                    test_file.unlink()
                    
                    self.temp_dir = candidate_path
                    logger.info(f"âœ… ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®šå®Œäº†: {self.temp_dir}")
                    break
                    
                except (OSError, PermissionError) as e:
                    logger.debug(f"âŒ ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå€™è£œå¤±æ•—: {candidate} - {e}")
                    continue
            
            if not self.temp_dir:
                # æœ€å¾Œã®æ‰‹æ®µ
                self.temp_dir = Path(tempfile.gettempdir())
                logger.warning(f"âš ï¸ ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«è¨­å®š: {self.temp_dir}")
        else:
            # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒï¼ˆç¾è¡Œã®å‡¦ç†ï¼‰
            self.temp_dir = Path(OCR_TEMP_FOLDER)
            self.temp_dir.mkdir(parents=True, exist_ok=True)
    
    def save_uploaded_file(self, file_data: bytes, filename: str) -> str:
        """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ä¿å­˜ï¼ˆAzureå¯¾å¿œï¼‰"""
        # ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
        safe_filename = f"{uuid.uuid4()}_{filename}"
        if not self.temp_dir:
            raise ValueError("Temporary directory is not initialized.")
        file_path = self.temp_dir / safe_filename
        
        try:
            with open(file_path, 'wb') as f:
                f.write(file_data)
            logger.debug(f"ğŸ“ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†: {file_path}")
            return str(file_path)
        except Exception as e:
            logger.error(f"âŒ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def cleanup_file(self, file_path: str):
        """å‡¦ç†å®Œäº†å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ï¼ˆAzureå¯¾å¿œï¼‰"""
        try:
            if os.path.exists(file_path):
                os.unlink(file_path)
                logger.debug(f"ğŸ§¹ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å®Œäº†: {file_path}")
        except OSError as e:
            logger.warning(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å¤±æ•—: {file_path} - {e}")

# OCRå‡¦ç†ï¼ˆAzureå¯¾å¿œä¿®æ­£ç‰ˆï¼‰
def process_document(file_path: str, ocr_id: int, db: Session):
    """
    ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†ã—ã¦OCRã‚’å®Ÿè¡Œã—ã€çµæœã‚’ä¿å­˜ã—ã¾ã™ã€‚
    Azure App Serviceå¯¾å¿œç‰ˆ
    
    :param file_path: å‡¦ç†ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    :param ocr_id: OCRçµæœã®ID
    :param db: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³
    """
    try:
        logger.info(f"OCRå‡¦ç†é–‹å§‹: {file_path}")
        
        # Tesseractã®è¨­å®šç¢ºèªï¼ˆAzureå¯¾å¿œï¼‰
        tesseract_available = setup_tesseract_for_azure()
        
        if not tesseract_available:
            # TesseractãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
            logger.warning("âš ï¸ TesseractãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
            return process_document_fallback(file_path, ocr_id, db)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­ã‚’å–å¾—
        _, file_ext = os.path.splitext(file_path)
        file_ext = file_ext.lower()
        
        raw_text = ""
        
        # PDFã®å ´åˆ
        if file_ext == '.pdf':
            try:
                # PDFã‚’ç”»åƒã«å¤‰æ›
                images = convert_from_path(file_path)
                
                # å„ãƒšãƒ¼ã‚¸ã‚’OCRå‡¦ç†
                for i, image in enumerate(images):
                    page_text = pytesseract.image_to_string(image, lang='eng+jpn')
                    raw_text += f"\n--- Page {i+1} ---\n{page_text}"
                    logger.debug(f"ãƒšãƒ¼ã‚¸ {i+1} ã®å‡¦ç†å®Œäº†")
            except Exception as e:
                logger.error(f"PDFå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
                # PDFã‚¨ãƒ©ãƒ¼ã®å ´åˆã‚‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚’è©¦è¡Œ
                logger.info("PDFâ†’OCRå‡¦ç†ã«å¤±æ•—ã—ãŸãŸã‚ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
                return process_document_fallback(file_path, ocr_id, db)
        
        # ç”»åƒã®å ´åˆ
        elif file_ext in ['.png', '.jpg', '.jpeg']:
            try:
                image = Image.open(file_path)
                raw_text = pytesseract.image_to_string(image, lang='eng+jpn')
                logger.debug("ç”»åƒã®OCRå‡¦ç†å®Œäº†")
            except Exception as e:
                logger.error(f"ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
                update_ocr_result(db, ocr_id, "", "{}", "failed", f"ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
                return
        
        else:
            # ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼
            logger.warning(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: {file_ext}")
            update_ocr_result(db, ocr_id, "", "{}", "failed", "ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™")
            return
        
        # OCRçµæœã‚’ä¿å­˜ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¯ä¿å­˜ã—ãªã„ï¼‰
        processed_data = {
            "original_filename": os.path.basename(file_path),
            "text_content": raw_text,
            "processing_method": "tesseract_ocr",
            "processing_timestamp": datetime.utcnow().isoformat()
        }
        
        # raw_textã¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã‚’ä¿å­˜ã€processed_dataã«è©³ç´°ã‚’ä¿å­˜
        update_ocr_result(db, ocr_id, raw_text, json.dumps(processed_data), "completed")
        logger.info(f"OCRå‡¦ç†å®Œäº†: {file_path}")
        
    except Exception as e:
        logger.error(f"OCRå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
        # æœ€çµ‚çš„ãªã‚¨ãƒ©ãƒ¼ã®å ´åˆã‚‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚’è©¦è¡Œ
        try:
            logger.info("OCRå‡¦ç†ã‚¨ãƒ©ãƒ¼ã®ãŸã‚ã€æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
            process_document_fallback(file_path, ocr_id, db)
        except Exception as fallback_error:
            logger.error(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚‚å¤±æ•—: {fallback_error}")
            update_ocr_result(db, ocr_id, "", json.dumps({"error": str(e)}), "failed", str(e))

# æ—¢å­˜ã®é–¢æ•°ï¼ˆä¿®æ­£ãªã—ã€å‹æ³¨é‡ˆã®æ”¹å–„ã®ã¿ï¼‰
def update_ocr_result(db: Session, ocr_id: int, raw_text: str, processed_data: str, status: str, error_message: Optional[str] = None):
    """
    OCRçµæœã‚’æ›´æ–°ã—ã¾ã™ï¼ˆmodels.pyã®OCRResultãƒ†ãƒ¼ãƒ–ãƒ«å¯¾å¿œï¼‰
    
    :param db: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³
    :param ocr_id: OCRçµæœã®ID
    :param raw_text: æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆï¼ˆTextå‹ã«å¯¾å¿œï¼‰
    :param processed_data: å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ï¼ˆJSONæ–‡å­—åˆ—ï¼‰
    :param status: å‡¦ç†çŠ¶æ…‹
    :param error_message: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    """
    try:
        ocr_result = db.query(models.OCRResult).filter(models.OCRResult.ocr_id == ocr_id).first()
        
        if ocr_result:
            ocr_result.raw_text = raw_text  # type: ignore # Textå‹ãªã®ã§æ–‡å­—åˆ—ã‚’ä¿å­˜
            ocr_result.processed_data = processed_data # type: ignore
            ocr_result.status = status # type: ignore
            
            if error_message:
                # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã‚ã‚Œã°ä¿å­˜
                try:
                    error_data = json.loads(processed_data) if processed_data and processed_data != "{}" else {}
                except json.JSONDecodeError:
                    error_data = {}
                error_data["error"] = error_message
                ocr_result.processed_data = json.dumps(error_data) # type: ignore
            
            db.commit()
            logger.info(f"OCRçµæœæ›´æ–°: ID={ocr_id}, ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹={status}")
        else:
            logger.warning(f"OCRçµæœæ›´æ–°å¤±æ•—: ID={ocr_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    except Exception as e:
        logger.error(f"OCRçµæœæ›´æ–°ã‚¨ãƒ©ãƒ¼: {str(e)}")
        db.rollback()

def process_document_from_bytes(file_data: bytes, filename: str, ocr_id: int, db: Session):
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç›´æ¥OCRå‡¦ç†ã‚’å®Ÿè¡Œï¼ˆAzureå¯¾å¿œï¼‰
    
    :param file_data: ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿
    :param filename: ãƒ•ã‚¡ã‚¤ãƒ«å
    :param ocr_id: OCRçµæœã®ID
    :param db: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³
    """
    temp_manager = TempFileManager()
    temp_path = None
    
    try:
        # 1. ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        temp_path = temp_manager.save_uploaded_file(file_data, filename)
        logger.info(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {temp_path}")
        
        # 2. æ—¢å­˜ã®OCRå‡¦ç†ã‚’å®Ÿè¡Œ
        process_document(temp_path, ocr_id, db)
        
    except Exception as e:
        logger.error(f"ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®OCRå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
        update_ocr_result(db, ocr_id, "", json.dumps({"error": str(e)}), "failed", str(e))
    
    finally:
        # 3. ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        if temp_path:
            temp_manager.cleanup_file(temp_path)

# æ—¢å­˜ã®é–¢æ•°ï¼ˆä¿®æ­£ãªã—ï¼‰
def extract_po_data(ocr_data) -> Dict[str, Any]:
    """
    OCRã§æŠ½å‡ºã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç™ºæ³¨æ›¸ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¾ã™ã€‚
    
    :param ocr_data: OCR IDï¼ˆæ•´æ•°ï¼‰ã¾ãŸã¯ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæ–‡å­—åˆ—ï¼‰
    :return: æ§‹é€ åŒ–ã•ã‚ŒãŸç™ºæ³¨æ›¸ãƒ‡ãƒ¼ã‚¿
    """
    # ocr_dataãŒæ•´æ•°ã®å ´åˆï¼ˆOCR IDï¼‰ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
    ocr_text = ""
    if isinstance(ocr_data, int):
        try:
            # DBã‹ã‚‰OCRçµæœã‚’å–å¾—ã—ã€raw_textã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
            db = SessionLocal()
            ocr_result = db.query(models.OCRResult).filter(models.OCRResult.ocr_id == ocr_data).first()
            if ocr_result and ocr_result.raw_text is not None:
                ocr_text = str(ocr_result.raw_text)
            else:
                # processed_dataã‹ã‚‰ã‚‚è©¦ã™
                if ocr_result and ocr_result.processed_data: # type: ignore
                    try:
                        processed_data = json.loads(str(ocr_result.processed_data))
                        ocr_text = processed_data.get("text_content", "")
                    except json.JSONDecodeError:
                        logger.error(f"JSONè§£æã‚¨ãƒ©ãƒ¼: {ocr_result.processed_data}")
            db.close()
        except Exception as e:
            logger.error(f"OCRãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
    else:
        # æ–‡å­—åˆ—ãŒç›´æ¥æ¸¡ã•ã‚ŒãŸå ´åˆ
        ocr_text = ocr_data
    
    # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®åˆ¤åˆ¥
    po_format, confidence = identify_po_format(ocr_text)
    logger.info(f"POãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆåˆ¤å®š: {po_format}, ä¿¡é ¼åº¦: {confidence:.2f}")
    
    # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¿œã˜ãŸãƒ‡ãƒ¼ã‚¿æŠ½å‡º
    if po_format == "format1" and confidence >= 0.4:
        logger.info("Format1 (Buyer's Info) ã®ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚’å®Ÿè¡Œã—ã¾ã™")
        result = extract_format1_data(ocr_text)
    elif po_format == "format2" and confidence >= 0.4:
        logger.info("Format2 (Purchase Order) ã®ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚’å®Ÿè¡Œã—ã¾ã™")
        result = extract_format2_data(ocr_text)
    elif po_format == "format3" and confidence >= 0.4:
        logger.info("Format3 (ORDER CONFIMATION) ã®ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚’å®Ÿè¡Œã—ã¾ã™")
        result = extract_format3_data(ocr_text)
    else:
        logger.info("ä¸€èˆ¬çš„ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã®ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚’å®Ÿè¡Œã—ã¾ã™")
        result = extract_generic_data(ocr_text)
    
    # çµæœã®æ¤œè¨¼ã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    validate_and_clean_result(result)
    
    logger.info(f"POæŠ½å‡ºçµæœ: {result}")
    return result

def validate_and_clean_result(result: Dict[str, Any]):
    """
    æŠ½å‡ºçµæœã‚’æ¤œè¨¼ã—ã¦ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚
    
    :param result: æŠ½å‡ºã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
    """
    # è£½å“æƒ…å ±ãŒãªã„å ´åˆã®å‡¦ç†
    if not result["products"]:
        logger.warning("è£½å“æƒ…å ±ãŒæŠ½å‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        result["products"].append({
            "name": "Unknown Product",
            "quantity": "",
            "unitPrice": "",
            "amount": ""
        })
    
    # æ•°é‡ãŒæŠ½å‡ºã•ã‚Œã¦ã„ã‚‹ãŒå˜ä½ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã€å˜ä½ã‚’å‰Šé™¤
    for product in result["products"]:
        if product["quantity"] and any(unit in product["quantity"] for unit in ["kg", "KG", "mt", "MT"]):
            product["quantity"] = re.sub(r'[^\d,.]', '', product["quantity"])
        
        # é‡‘é¡ã®ãƒ‰ãƒ«è¨˜å·ãªã©ã‚’å‰Šé™¤
        if product["unitPrice"] and any(symbol in product["unitPrice"] for symbol in ["$", "USD"]):
            product["unitPrice"] = re.sub(r'[^\d,.]', '', product["unitPrice"])
        
        if product["amount"] and any(symbol in product["amount"] for symbol in ["$", "USD"]):
            product["amount"] = re.sub(r'[^\d,.]', '', product["amount"])
    
    # åˆè¨ˆé‡‘é¡ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    if result["totalAmount"] and any(symbol in result["totalAmount"] for symbol in ["$", "USD"]):
        result["totalAmount"] = re.sub(r'[^\d,.]', '', result["totalAmount"])

def analyze_extraction_quality(result: Dict[str, Any]) -> Dict[str, Any]:
    """æŠ½å‡ºçµæœã®å“è³ªã‚’åˆ†æã—ã¾ã™"""
    quality_assessment = {
        "completeness": 0.0,
        "confidence": 0.0,
        "missing_fields": [],
        "recommendation": ""
    }
    
    essential_fields = ["customer", "poNumber", "totalAmount"]
    product_fields = ["name", "quantity", "unitPrice", "amount"]
    
    missing_fields = [field for field in essential_fields if not result[field]]
    
    has_product = len(result["products"]) > 0
    if has_product:
        first_product = result["products"][0]
        missing_product_fields = [field for field in product_fields if not first_product[field]]
        if missing_product_fields:
            missing_fields.append(f"products({', '.join(missing_product_fields)})")
    else:
        missing_fields.append("products")
    
    total_fields = len(essential_fields) + (len(product_fields) if has_product else 1)
    filled_fields = total_fields - len(missing_fields)
    completeness = filled_fields / total_fields
    
    quality_assessment["completeness"] = round(completeness, 2)
    quality_assessment["missing_fields"] = missing_fields
    
    confidence = min(1.0, completeness * 1.2)
    quality_assessment["confidence"] = round(confidence, 2)
    
    if completeness < 0.5:
        quality_assessment["recommendation"] = "æŠ½å‡ºå“è³ªãŒä½ã„ãŸã‚ã€æ‰‹å‹•ã§å…¥åŠ›ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
    elif completeness < 0.8:
        quality_assessment["recommendation"] = "ä¸è¶³ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ‰‹å‹•ã§è£œå®Œã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚"
    else:
        quality_assessment["recommendation"] = "æŠ½å‡ºå“è³ªã¯è‰¯å¥½ã§ã™ã€‚å†…å®¹ã‚’ç¢ºèªã—ã¦é€²ã‚ã¦ãã ã•ã„ã€‚"
    
    return quality_assessment

def get_extraction_stats(ocr_text: str, result: Dict[str, Any]) -> Dict[str, Any]:
    """OCRæŠ½å‡ºã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ã—ã¾ã™"""
    stats = {
        "text_length": len(ocr_text),
        "word_count": len(ocr_text.split()),
        "format_candidates": {},
        "extraction_time_ms": 0,
        "quality_assessment": analyze_extraction_quality(result)
    }
    
    format_name, confidence = identify_po_format(ocr_text)
    stats["format_candidates"][format_name] = confidence
    
    all_formats = ["format1", "format2", "format3", "unknown"]
    for fmt in all_formats:
        if fmt != format_name:
            stats["format_candidates"][fmt] = 0.0
    
    return stats

def process_ocr_with_enhanced_extraction(file_data: bytes, filename: str, ocr_id: int):
    """
    æ‹¡å¼µæŠ½å‡ºæ©Ÿèƒ½ã‚’æŒã¤OCRå‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™ï¼ˆAzureå¯¾å¿œç‰ˆï¼‰
    â€» æ–°ã—ã„DBã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å†…éƒ¨ã§ä½œæˆ
    
    :param file_data: ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿
    :param filename: ãƒ•ã‚¡ã‚¤ãƒ«å
    :param ocr_id: OCRçµæœã®ID
    """
    # æ–°ã—ã„DBã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
    db = SessionLocal()
    
    try:
        logger.info(f"æ‹¡å¼µOCRå‡¦ç†é–‹å§‹: {filename}")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å‡¦ç†
        process_document_from_bytes(file_data, filename, ocr_id, db)
        
        # OCRçµæœã‚’å–å¾—
        ocr_result = db.query(models.OCRResult).filter(models.OCRResult.ocr_id == ocr_id).first()
        if not ocr_result or ocr_result.status != "completed":  # type: ignore
            logger.warning(f"OCRå‡¦ç†ãŒå®Œäº†ã—ã¦ã„ã¾ã›ã‚“: ID={ocr_id}")
            return
        
        # raw_textã¾ãŸã¯processed_dataã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã‚’å–å¾—
        ocr_text = ""
        if ocr_result.raw_text is not None:
            ocr_text = str(ocr_result.raw_text)
        elif ocr_result.processed_data is not None:
            try:
                processed_data = json.loads(str(ocr_result.processed_data))
                ocr_text = processed_data.get("text_content", "")
            except json.JSONDecodeError:
                logger.error(f"JSONè§£æã‚¨ãƒ©ãƒ¼: {ocr_result.processed_data}")
        
        # POæƒ…å ±ã®æŠ½å‡º
        extracted_data = extract_po_data(ocr_text)
        
        # æŠ½å‡ºçµ±è¨ˆæƒ…å ±ã®å–å¾—
        stats = get_extraction_stats(ocr_text, extracted_data)
        
        # æŠ½å‡ºçµæœã¨çµ±è¨ˆæƒ…å ±ã‚’å«ã‚€å®Œå…¨ãªçµæœã‚’ä¿å­˜
        complete_result = {
            "data": extracted_data,
            "stats": stats,
            "original_filename": filename,
            "text_content": ocr_text
        }
        
        # çµæœã®ä¿å­˜
        ocr_result.processed_data = json.dumps(complete_result) # type: ignore
        db.commit()
        
        logger.info(f"æ‹¡å¼µOCRå‡¦ç†å®Œäº†: ID={ocr_id}")
        
    except Exception as e:
        logger.error(f"æ‹¡å¼µOCRå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
        try:
            ocr_result = db.query(models.OCRResult).filter(models.OCRResult.ocr_id == ocr_id).first()
            if ocr_result:
                ocr_result.status = "failed" # type: ignore
                error_data = {"error": str(e)}
                ocr_result.processed_data = json.dumps(error_data)  # type: ignore
                db.commit()
        except Exception as inner_e:
            logger.error(f"ã‚¨ãƒ©ãƒ¼æƒ…å ±ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {str(inner_e)}")
    
    finally:
        db.close()