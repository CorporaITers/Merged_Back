# main.py - ç¾è¡Œã‚³ãƒ¼ãƒ‰ã‚’ãƒ™ãƒ¼ã‚¹ã«OCRæ©Ÿèƒ½ã‚’çµ±åˆã—ãŸæ”¹è‰¯ç‰ˆ

from fastapi import FastAPI, HTTPException, Request
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from datetime import datetime, timedelta
import os
import json
import subprocess
from typing import Optional, Dict, Any, cast
import logging
from dateutil import parser
import mysql.connector
from decimal import Decimal
import pymysql
from collections import defaultdict
from openai import AzureOpenAI
import httpx
from pathlib import Path
import sys
from urllib.parse import unquote
from dotenv import load_dotenv
import traceback
from fastapi.responses import JSONResponse
import camelot.io as camelot
import warnings
from app.app_router import router as po_router
from fastapi.exceptions import RequestValidationError
import tempfile
import csv

# ========== OCRæ©Ÿèƒ½ã®çµ±åˆï¼ˆè¿½åŠ ï¼‰ ==========
from app.routes import app as ocr_routes_app  # OCRé–¢é€£ã®ãƒ«ãƒ¼ãƒˆ
from app.config import (
    DEV_MODE, LOG_LEVEL, OCR_TEMP_FOLDER, MAX_FILE_SIZE, ALLOWED_EXTENSIONS
)

# ãƒ­ãƒ¼ã‚«ãƒ«ç”¨ .env èª­ã¿è¾¼ã¿ï¼ˆAzureç’°å¢ƒã§ã¯ç„¡è¦–ã•ã‚Œã‚‹ï¼‰
load_dotenv(override=True)

# ãƒ­ã‚°è¨­å®šï¼ˆç¾è¡Œã®ã‚‚ã®ã‚’ç¶­æŒï¼‰
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)]
)

logger = logging.getLogger(__name__)

# pdfminerã®ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’ERRORã«è¨­å®šï¼ˆç¾è¡Œã®ã¾ã¾ï¼‰
for logger_name in ["pdfminer", "pdfminer.layout", "pdfminer.converter", "pdfminer.pdfinterp"]:
    logging.getLogger(logger_name).setLevel(logging.ERROR)

# è­¦å‘Šã‚’æŠ‘åˆ¶ï¼ˆç¾è¡Œã®ã¾ã¾ï¼‰
warnings.filterwarnings("ignore", message="Cannot set gray non-stroke color")

# Azure OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆç¾è¡Œã®ã¾ã¾ï¼‰
client = AzureOpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    api_version=os.getenv("OPENAI_API_VERSION"),
    azure_endpoint=os.getenv("OPENAI_API_BASE") or ""
)

# FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆ
app = FastAPI(
    title="PO Management System",
    description="Purchase Order Management with OCR capabilities and Shipping Schedule Integration",
    version="1.0.0",
    debug=DEV_MODE  # config.pyã®DEV_MODEã‚’ä½¿ç”¨
)

# ========== ãƒ«ãƒ¼ã‚¿ãƒ¼ã®çµ±åˆï¼ˆé‡è¦ãªä¿®æ­£ï¼‰ ==========
# æ—¢å­˜ã®POãƒ«ãƒ¼ã‚¿ãƒ¼
app.include_router(po_router)

# OCRæ©Ÿèƒ½ãƒ«ãƒ¼ã‚¿ãƒ¼ã®çµ±åˆï¼ˆæ–°è¦è¿½åŠ ï¼‰
app.mount("/api", ocr_routes_app)  # OCRã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’çµ±åˆ

# ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆç¾è¡Œã®ã¾ã¾ï¼‰
@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    logger.error(f"ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {exc.errors()}")
    return JSONResponse(
        status_code=422,
        content={
            "detail": exc.errors(),
            "message": "å…¥åŠ›å†…å®¹ã«èª¤ã‚ŠãŒã‚ã‚Šã¾ã™ã€‚"
        }
    )

# CORSè¨­å®šï¼ˆç¾è¡Œã®ã¾ã¾ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ========== èµ·å‹•æ™‚å‡¦ç†ã®æ”¹è‰¯ ==========
@app.on_event("startup")
def on_startup():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã®åˆæœŸåŒ–å‡¦ç†"""
    logger.info("ğŸš€ PO Management System starting up...")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆï¼ˆç¾è¡Œã®ã¾ã¾ï¼‰
    from app import models
    from app.database import engine
    models.Base.metadata.create_all(bind=engine)
    
    # OCRç”¨ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆï¼ˆæ–°è¦è¿½åŠ ï¼‰
    try:
        os.makedirs(OCR_TEMP_FOLDER, exist_ok=True)
        logger.info(f"ğŸ“ OCRä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆå®Œäº†: {OCR_TEMP_FOLDER}")
    except Exception as e:
        logger.error(f"âŒ OCRä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆå¤±æ•—: {e}")
    
    # Tesseractã®å‹•ä½œç¢ºèªï¼ˆæ–°è¦è¿½åŠ ï¼‰
    try:
        import pytesseract
        from app.config import TESSERACT_CMD
        
        if TESSERACT_CMD and os.path.exists(TESSERACT_CMD):
            pytesseract.pytesseract.tesseract_cmd = TESSERACT_CMD
            logger.info(f"ğŸ” Tesseractè¨­å®šå®Œäº†: {TESSERACT_CMD}")
        else:
            logger.info("ğŸ” Tesseractã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ã‚’ä½¿ç”¨ã—ã¾ã™")
            
    except Exception as e:
        logger.warning(f"âš ï¸ Tesseractè¨­å®šè­¦å‘Š: {e}")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆï¼ˆæ–°è¦è¿½åŠ ï¼‰
    try:
        from app.database import test_db_connection
        test_db_connection()
        logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
    
    # å¤ã„ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆæ–°è¦è¿½åŠ ï¼‰
    cleanup_temp_files()

# MySQLæ¥ç¶šæƒ…å ±ï¼ˆç¾è¡Œã®ã¾ã¾ï¼‰
DB_CONFIG = {
    "host": os.getenv("DB_HOST"),
    "user": os.getenv("DB_USER"),
    "password": os.getenv("DB_PASSWORD"),
    "database": os.getenv("DB_NAME")
}

def get_db_connection():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’å–å¾—ï¼ˆç¾è¡Œã®ã¾ã¾ï¼‰"""
    return mysql.connector.connect(**DB_CONFIG)

def format_date(date_obj: Optional[datetime]) -> str:
    """æ—¥ä»˜ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ 'YYYY-MM-DD' å½¢å¼ã®æ–‡å­—åˆ—ã«å¤‰æ›ï¼ˆç¾è¡Œã®ã¾ã¾ï¼‰"""
    return date_obj.strftime("%Y-%m-%d") if date_obj else "N/A"

def get_freight_rate(departure_port: str, destination_port: str, shipping_company: str) -> Optional[float]:
    """é‹è³ƒãƒ¬ãƒ¼ãƒˆã‚’å–å¾—ã—ã¦ float å‹ã§è¿”ã™ï¼ˆç¾è¡Œã®ã¾ã¾ï¼‰"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor(dictionary=True)

        query = """
            SELECT freight_rate_usd
            FROM faredate
            WHERE departure_port = %s AND destination_port = %s AND shipping_company = %s
            LIMIT 1;
        """
        cursor.execute(query, (departure_port, destination_port, shipping_company))
        row = cast(Optional[Dict[str, Any]], cursor.fetchone())
        cursor.close()
        conn.close()

        if row and "freight_rate_usd" in row:
            value = row["freight_rate_usd"]

            if isinstance(value, Decimal):
                return float(value)
            else:
                logger.warning(f"Unexpected data type for freight_rate_usd: {type(value)}")

    except Exception as e:
        logger.error(f"[ERROR] é‹è³ƒå–å¾—å¤±æ•—: {e}")

    return None

# ========== ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†æ©Ÿèƒ½ï¼ˆæ”¹è‰¯ãƒ»çµ±åˆï¼‰ ==========
def get_temp_file_path(prefix: str, suffix: str) -> str:
    """Azure App Serviceå¯¾å¿œã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ç”Ÿæˆ"""
    temp_dir = OCR_TEMP_FOLDER  # config.pyã®è¨­å®šã‚’ä½¿ç”¨
    return os.path.join(temp_dir, f"{prefix}_{os.getpid()}_{int(datetime.now().timestamp())}{suffix}")

def cleanup_temp_files(pattern: str = "*.pdf"):
    """ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    import glob
    pattern_path = os.path.join(OCR_TEMP_FOLDER, pattern)
    
    for file_path in glob.glob(pattern_path):
        try:
            # 1æ™‚é–“ä»¥ä¸Šå¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            if os.path.getctime(file_path) < (datetime.now().timestamp() - 3600):
                os.remove(file_path)
                logger.info(f"ğŸ§¹ å¤ã„ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤: {file_path}")
        except Exception as e:
            logger.warning(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å¤±æ•—: {e}")

# ========== æ—¢å­˜ã®APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆç¾è¡Œã®ã¾ã¾ç¶­æŒï¼‰ ==========

# å•†å“ãƒã‚¹ã‚¿å–å¾—API
TABLE_NAME = "shipping_company"

# ãƒ†ã‚¹ãƒˆç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆç¾è¡Œã®ã¾ã¾ï¼‰
@app.get("/test-env")
def test_env():
    openai_key = os.getenv("OPENAI_API_KEY")
    if openai_key:
        return {"status": "success", "openai_key_snippet": openai_key[:5] + "..." + openai_key[-5:]}
    else:
        return {"status": "failure", "error": "OPENAI_API_KEY not found"}

@app.get("/")
async def root():
    return {"message": "PO Management System with OCR - Hello, FastAPI!"}

# ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£å®šç¾©ï¼ˆç¾è¡Œã®ã¾ã¾ï¼‰
class ShippingRequest(BaseModel):
    departure_port: str
    destination_port: str
    etd_date: Optional[str] = None
    eta_date: Optional[str] = None

class ScheduleRequest(BaseModel):
    departure_port: str
    destination_port: str
    etd_date: Optional[str]
    eta_date: Optional[str]

class FeedbackRequest(BaseModel):
    url: str
    etd: str
    eta: str
    feedback: str

# ========== PDFã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è§£ææ©Ÿèƒ½ï¼ˆç¾è¡Œã®ã¾ã¾ï¼‰ ==========
async def extract_schedule_positions(
    url: str,
    departure: str,
    destination: str,
    etd_date: Optional[datetime] = None,
    eta_date: Optional[datetime] = None
):
    """PDFã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è§£æï¼ˆç¾è¡Œã®ã¾ã¾ - ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã¯æ—¢ã«æ”¹å–„æ¸ˆã¿ï¼‰"""
    
    import os
    import json
    import re
    import requests
    from datetime import datetime

    DESTINATION_ALIASES = {
        "New York": ["NEW YORK", "NYC", "NEWYORK", "N.Y.", "NY", "NYO"],
        "Los Angeles": ["LOS ANGELES", "LA", "L.A."],
        "Rotterdam": ["ROTTERDAM"],
        "Hamburg": ["HAMBURG"],
        "Norfolk": ["NORFOLK", "ORF"],
        "Savannah": ["SAVANNAH", "SAV"],
        "Charleston": ["CHARLESTON"],
        "Miami": ["MIAMI", "MIA"],
        "Oakland": ["OAKLAND", "OAK"],
        "Houston": ["HOUSTON", "HOU"],
        "Dallas": ["DALLAS", "FWO", "FORT WORTH", "FT WORTH"],
        "Memphis": ["MEMPHIS", "MEM"],
        "Atlanta": ["ATLANTA", "ATL"],
        "Chicago": ["CHICAGO", "CHI"],
        "Columbus": ["COLUMBUS", "CMH"],
        "Singapore": ["SINGAPORE", "SGP"],
        "Jakarta": ["JAKARTA"],
        "Port Klang": ["PORT KLANG", "PORT KLANG (W)", "PORT KLANG (N)", "PKG", "PKW"],
        "Penang": ["PENANG"],
        "Surabaya": ["SURABAYA"],
        "Bangkok": ["BANGKOK"],
        "Ho Chi Minh": ["HO CHI MINH", "HCM", "SAIGON"],
        "Haiphong": ["HAIPHONG", "HPH"],
        "Hanoi": ["HANOI"],
        "Manila": ["MANILA", "MNL"],
        "Busan": ["BUSAN", "PUSAN", "PUS"],
        "Hong Kong": ["HONG KONG", "HK", "HKG"],
        "Kaohsiung": ["KAOHSIUNG", "KHH"],
        "Sydney": ["SYDNEY", "SYD"],
        "Melbourne": ["MELBOURNE", "MEL"],
        "Adelaide": ["ADELAIDE", "ADL"],
        "Fremantle": ["FREMANTLE", "FRE"],
        "Brisbane": ["BRISBANE", "BNE"],
        "Xiamen": ["XIAMEN"],
        "Qingdao": ["QINGDAO", "TSINGTAO"],
        "Dalian": ["DALIAN"],
        "Shanghai": ["SHANGHAI", "SHA"],
        "Ningbo": ["NINGBO"],
        "Shekou": ["SHEKOU"],
        "Yantian": ["YANTIAN", "YTN"],
        "Nansha": ["NANSHA"],
        "Shenzhen": ["SHENZHEN"],
        "Tanjung Pelepas": ["TANJUNG PELEPAS", "TPP"],
        "Port Kelang": ["PORT KELANG", "PORTKLANG"],
    }

    if not etd_date and not eta_date:
        return {"error": "ETDã‹ETAã®ã„ãšã‚Œã‹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"}

    base_date = etd_date or eta_date

    # PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    logger.info(f"ğŸ“¥ PDFãƒªãƒ³ã‚¯ã«ã‚¢ã‚¯ã‚»ã‚¹ä¸­: {url}")
    response = requests.get(url)
    
    if response.status_code != 200:
        logger.error(f"âŒ PDFã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: {response.status_code}")
        return None

    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ãŸå®‰å…¨ãªå‡¦ç†ï¼ˆç¾è¡Œã‚³ãƒ¼ãƒ‰ã®æ”¹è‰¯ç‰ˆï¼‰
    temp_pdf_file = None
    try:
        # OCR_TEMP_FOLDERã‚’ä½¿ç”¨ã—ã¦ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        temp_pdf_file = tempfile.NamedTemporaryFile(
            suffix=".pdf", 
            delete=False,
            dir=OCR_TEMP_FOLDER  # config.pyã®è¨­å®šã‚’ä½¿ç”¨
        )
        
        logger.info(f"ğŸ“ ä¸€æ™‚PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ: {temp_pdf_file.name}")
        temp_pdf_file.write(response.content)
        temp_pdf_file.flush()
        temp_pdf_file.close()

        # ã‚¨ã‚¤ãƒªã‚¢ã‚¹ç”Ÿæˆï¼ˆå¤§æ–‡å­—åŒ–ã—ã¦æ­£è¦åŒ–ï¼‰
        aliases = DESTINATION_ALIASES.get(destination, [destination])
        aliases = [a.upper() for a in aliases]

        # PDFãƒ†ãƒ¼ãƒ–ãƒ«æŠ½å‡º
        logger.info(f"ğŸ” PDFãƒ†ãƒ¼ãƒ–ãƒ«æŠ½å‡ºé–‹å§‹: {temp_pdf_file.name}")
        tables = camelot.read_pdf(temp_pdf_file.name, pages="all", flavor="stream")
        logger.info(f"æŠ½å‡ºã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«æ•°: {len(tables)}")

        # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æ–‡å­—åˆ—å½¢å¼ã«å¤‰æ›
        table_data = ""
        for i, table in enumerate(tables):
            table_data += f"\n--- ãƒ†ãƒ¼ãƒ–ãƒ« {i + 1} ---\n"
            table_data += table.df.to_string()

        prompt = f"""
ä»¥ä¸‹ã¯PDFã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å€™è£œã®è¡Œã§ã™ã€‚
å‡ºç™ºåœ°ã€Œ{departure}ã€ã¨ç›®çš„åœ°ã€Œ{destination}ã€ï¼ˆåˆ¥å: {', '.join(aliases)}ï¼‰ã«é–¢é€£ã™ã‚‹ã€
æœ€ã‚‚{format_date(base_date)}ã«è¿‘ã„ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆèˆ¹åãƒ»èˆªæµ·ç•ªå·ãƒ»ETDãƒ»ETAï¼‰ã‚’1ä»¶ã ã‘æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ãã®æŠ½å‡ºã—ãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¤‡æ•°ã®èˆ¹åã‚’æœ‰ã™ã‚‹ã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã€ã‚‚ã—æœ‰ã™ã‚‹å ´åˆã¯1st Vesselã®èˆ¹åã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚
ï¼ˆæœ‰ã—ãªã„å ´åˆã¯ãã®ã¾ã¾ã®èˆ¹åã‚’é¸æŠã—ã¦ãã ã•ã„ï¼‰

ãªãŠã€å‡ºæ¸¯æ—¥{etd_date}ã¯å‡ºç™ºåœ°ã€Œ{departure}ã€ã®æ—¥ä»˜ã‚’åŸºæº–ã«ã€åˆ°ç€æ—¥{eta_date}ã¯ç›®çš„åœ°ã€Œ{destination}ã€ã®æ—¥ä»˜ã‚’åŸºæº–ã¨ã—ã¦ã€çµæœã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

å‡ºåŠ›å½¢å¼ï¼ˆå¿…ãšJSONå½¢å¼ï¼‰:
{{
  "vessel": "èˆ¹å",
  "voy": "èˆªæµ·ç•ªå·",
  "etd": "MM/DD ã¾ãŸã¯ MM/DD - MM/DD",
  "eta": "MM/DD"
}}

ãªãœãã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’é¸æŠã—ãŸã®ã‹ã€ç†ç”±ã‚‚ç°¡æ½”ã«å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
---
{table_data}
"""

        chat_response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯è²¿æ˜“å®Ÿå‹™ã«è©³ã—ã„ç†Ÿç·´ã®èˆ¹ä¾¿é¸å®šã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚"},
                {"role": "user", "content": prompt},
            ]
        )

        reply_text = chat_response.choices[0].message.content

        if reply_text is None:
            logger.warning("[WARNING] ChatGPTã®è¿”ç­”ãŒç©ºã¾ãŸã¯Noneã§ã™")
            return {
                "error": "ChatGPTã®è¿”ç­”ãŒç©ºã¾ãŸã¯Noneã§ã™", 
                "raw_response": "",
                "vessel": "",
                "voy": "",
                "etd": "",
                "eta": "",
                "fare": "",
                "schedule_url": url
            }
            
        match = re.search(r'\{[\s\S]*?\}', reply_text)
        if not match:
            logger.warning("[WARNING] ChatGPTã®è¿”ç­”ãŒJSONå½¢å¼ã§ãªã„ãŸã‚è§£æä¸å¯")
            return {
                "error": "ChatGPTã®è¿”ç­”ãŒJSONå½¢å¼ã§å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“", 
                "raw_response": reply_text,
                "vessel": "",
                "voy": "",
                "etd": "",
                "eta": "",
                "fare": "",
                "schedule_url": url
            }

        try:
            info = json.loads(match.group())
            etd_date_str = info.get("etd")
            eta_date_str = info.get("eta")
            vessel = info.get("vessel")
            voyage = info.get("voy")
            company = info.get("company")

            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®è¨­å®šï¼ˆcompanyãŒå–å¾—ã§ããªã„å ´åˆï¼‰
            if not company:
                company = "Unknown"

            # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä½œæˆ
            log_path = os.path.join(OCR_TEMP_FOLDER, "gpt_feedback_log.csv")
            new_entry = [
                datetime.now().isoformat(),
                url,
                departure,
                destination,
                format_date(base_date),
                etd_date_str,
                eta_date_str,
                vessel,
                voyage,
                company,
                "pending"
            ]

            file_exists = os.path.exists(log_path)
            with open(log_path, "a", newline='', encoding='utf-8') as log_file:
                writer = csv.writer(log_file)
                if not file_exists:
                    writer.writerow(["timestamp", "url", "departure", "destination", "input_date", "etd", "eta", "vessel", "voy", "company", "feedback"])
                writer.writerow(new_entry)

            return {
                "company": company,
                "fare": "$",
                "etd": etd_date_str,
                "eta": eta_date_str,
                "vessel": vessel,
                "voy": voyage,
                "schedule_url": url,
                "raw_response": reply_text
            }
        except Exception as e:
            return {"error": "ChatGPTã®è¿”ç­”ãŒãƒ‘ãƒ¼ã‚¹ã§ãã¾ã›ã‚“ã§ã—ãŸ", "raw_response": reply_text}

    except Exception as e:
        logger.error(f"PDFè§£æå¤±æ•—: {e}")
        return None

    finally:
        # ç¢ºå®Ÿãªãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if temp_pdf_file:
            try:
                if os.path.exists(temp_pdf_file.name):
                    os.unlink(temp_pdf_file.name)
                    logger.info(f"ğŸ§¹ ä¸€æ™‚PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {temp_pdf_file.name}")
            except Exception as cleanup_error:
                logger.warning(f"[WARN] PDFå‰Šé™¤ã«å¤±æ•—: {cleanup_error}")

# ========== æ—¢å­˜ã®PDFãƒªãƒ³ã‚¯å–å¾—æ©Ÿèƒ½ï¼ˆç¾è¡Œã®ã¾ã¾ï¼‰ ==========

async def get_pdf_links_from_one(destination_keyword: str) -> list[str]:
    """ONEç¤¾ã®PDFãƒªãƒ³ã‚¯å–å¾—ï¼ˆç¾è¡Œã®ã¾ã¾ï¼‰"""
    result = None
    try:
        script_path = Path(__file__).resolve().parent / "app" / "get_pdf_links.py"
        cwd_path = script_path.parent

        result = subprocess.run(
            [sys.executable, str(script_path), destination_keyword, "--silent"],
            capture_output=True,
            text=True,
            check=True,
            cwd=str(cwd_path),
            env=os.environ.copy(),
        )

        if result.stdout:
            logger.info(f"[DEBUG] get_pdf_links.py stdout:\n{result.stdout}")
        
        return json.loads(result.stdout)
    
    except json.JSONDecodeError as je:
        logger.error(f"[ERROR] JSON Decode Error: {je}")
        if result and result.stdout:
            logger.error(f"[DEBUG] å®Ÿéš›ã®å‡ºåŠ›å†…å®¹: {result.stdout}")
        else:
            logger.error("[DEBUG] stdout is None")
        return []
    
    except subprocess.CalledProcessError as cpe:
        logger.error(f"[CalledProcessError] stderr:\n{cpe.stderr}")
        if cpe.stdout:
            logger.error(f"[CalledProcessError] stdout:\n{cpe.stdout}")
        else:
            logger.error("[CalledProcessError] stdout is None")
        return []
    
    except Exception as e:
        logger.error(f"[ERROR] ONE get_pdf_links å®Ÿè¡Œå¤±æ•—: {e}")
        return []

async def get_pdf_links_from_cosco(destination_keyword: str) -> list[str]:
    """COSCOç¤¾ã®PDFãƒªãƒ³ã‚¯å–å¾—ï¼ˆç¾è¡Œã®ã¾ã¾ï¼‰"""
    result = None
    try:
        script_path = Path(__file__).resolve().parent / "app" / "get_cosco_pdf_links.py"
        cwd_path = script_path.parent

        result = subprocess.run(
            [sys.executable, str(script_path), destination_keyword, "--silent"],
            capture_output=True,
            text=True,
            check=True,
            cwd=str(cwd_path),
            env=os.environ.copy(),
        )

        if result.stdout:
            logger.info(f"[COSCO PDFãƒªãƒ³ã‚¯å–å¾—] stdout:\n{result.stdout}")

        return json.loads(result.stdout)

    except json.JSONDecodeError as je:
        logger.error(f"[ERROR] JSON Decode Error: {je}")
        if result and result.stdout:
            logger.error(f"[DEBUG] å®Ÿéš›ã®å‡ºåŠ›å†…å®¹: {result.stdout}")
        else:
            logger.error("[DEBUG] stdout is None")
        return []

    except subprocess.CalledProcessError as spe:
        logger.error(f"[ERROR] CalledProcessError: {spe}")
        if spe.stdout:
            logger.error(f"[stderr]\n{spe.stderr}")
        else:
            logger.error("[stderr] None")

        if spe.stdout:
            logger.error(f"[stdout]\n{spe.stdout}")
        else:
            logger.error("[stdout] None")
        return []

    except Exception as e:
        logger.error(f"[ERROR] COSCO get_pdf_links å®Ÿè¡Œå¤±æ•—: {e}")
        return []

async def get_pdf_links_from_kinka(destination_keyword: str) -> list[str]:
    """KINKAç¤¾ã®PDFãƒªãƒ³ã‚¯å–å¾—ï¼ˆç¾è¡Œã®ã¾ã¾ï¼‰"""
    result = None
    try:
        script_path = Path(__file__).resolve().parent / "app" / "get_kinka_pdf_links.py"
        cwd_path = script_path.parent

        result = subprocess.run(
            [sys.executable, str(script_path), destination_keyword, "--silent"],
            capture_output=True,
            text=True,
            check=True,
            cwd=str(cwd_path),
            env=os.environ.copy(),
        )

        if result.stdout:
            logger.info(f"[KINKA PDFãƒªãƒ³ã‚¯å–å¾—] stdout:\n{result.stdout}")
        
        return json.loads(result.stdout)

    except json.JSONDecodeError as je:
        logger.error(f"[ERROR] JSON Decode Error: {je}")
        if result and result.stdout:
            logger.error(f"[DEBUG] å®Ÿéš›ã®å‡ºåŠ›å†…å®¹: {result.stdout}")
        else:
            logger.error("[DEBUG] stdout is None")
        return []
    
    except Exception as e:
        logger.error(f"[ERROR] KINKA get_pdf_links å®Ÿè¡Œå¤±æ•—: {e}")
        return []

async def get_pdf_links_from_shipmentlink(departure_port: str, destination_port: str) -> list[str]:
    """Shipmentlink ã®PDFãƒªãƒ³ã‚¯å–å¾—ï¼ˆç¾è¡Œã®ã¾ã¾ï¼‰"""
    result = None
    try:
        script_path = Path(__file__).resolve().parent / "app" / "get_shipmentlink_pdf_links.py"
        cwd_path = script_path.parent

        result = subprocess.run(
            [sys.executable, str(script_path), departure_port, destination_port, "--silent"],
            capture_output=True,
            text=True,
            check=True,
            cwd=str(cwd_path),
            env=os.environ.copy(),
        )

        logger.info(f"[Shipmentlink PDFå–å¾—] raw stdout:\n{result.stdout}")
        raw_links = json.loads(result.stdout)
        decoded_links = [unquote(url) for url in raw_links]
        logger.info(f"[Shipmentlink PDFå–å¾—] decoded:\n{decoded_links}")
        
        return decoded_links
    except Exception as e:
        logger.error(f"[Shipmentlinkå–å¾—å¤±æ•—] {e}")
        return []

# ========== èˆ¹èˆ¶ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ¨å¥¨APIï¼ˆç¾è¡Œã®ã¾ã¾ï¼‰ ==========
@app.post("/recommend-shipping")
async def recommend_shipping(req: ShippingRequest):
    """èˆ¹èˆ¶ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ¨å¥¨APIï¼ˆç¾è¡Œã®ã¾ã¾ï¼‰"""
    logger.info("ğŸ“¦ ãƒªã‚¯ã‚¨ã‚¹ãƒˆå—ä¿¡:")
    logger.info(f"  Departure Port: {req.departure_port}")
    logger.info(f"  Destination Port: {req.destination_port}")
    logger.info(f"  ETD: {req.etd_date}")
    logger.info(f"  ETA: {req.eta_date}")

    if not req.etd_date and not req.eta_date:
        return {"error": "ETDã‹ETAã®ã„ãšã‚Œã‹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"}

    destination = req.destination_port
    departure = req.departure_port
    keyword = destination
    etd_date = datetime.strptime(req.etd_date, "%Y-%m-%d") if req.etd_date else None
    eta_date = datetime.strptime(req.eta_date, "%Y-%m-%d") if req.eta_date else None

    results = []

    # ONEç¤¾ã®å‡¦ç†
    logger.info(f"ğŸ” ONEç¤¾ get_pdf_links.py ã«æ¸¡ã™ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: '{keyword}'")
    pdf_urls_one = await get_pdf_links_from_one(keyword)
    if not pdf_urls_one:
        logger.warning("âš ï¸ ONEç¤¾ã®PDFãƒªãƒ³ã‚¯å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    else:
        for pdf_url in pdf_urls_one:
            result = await extract_schedule_positions(
                url=pdf_url,
                departure=departure,
                destination=destination,
                etd_date=etd_date,
                eta_date=eta_date
            )
            if result:
                result["company"] = "ONE"
                result["fare"] = str(get_freight_rate(departure, destination, "ONE")) if not None else "N/A"
                results.append(result)
                logger.info(f"[ONEç¤¾ãƒãƒƒãƒ] {result}")
                break

    # COSCOç¤¾ã®å‡¦ç†
    logger.info(f"ğŸ” COSCOç¤¾ get_cosco_pdf_links.py ã«æ¸¡ã™ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: '{keyword}'")
    pdf_urls_cosco = await get_pdf_links_from_cosco(keyword)
    if not pdf_urls_cosco:
        logger.warning("âš ï¸ COSCOç¤¾ã®PDFãƒªãƒ³ã‚¯å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    else:
        for pdf_url in pdf_urls_cosco:
            result = await extract_schedule_positions(
                url=pdf_url,
                departure=departure,
                destination=destination,
                etd_date=etd_date,
                eta_date=eta_date
            )
            if result:
                result["company"] = "COSCO"
                result["fare"] = str(get_freight_rate(departure, destination, "COSCO")) if not None else "N/A"
                results.append(result)
                logger.info(f"[COSCOç¤¾ãƒãƒƒãƒ] {result}")
                break

    # KINKAç¤¾ã®å‡¦ç†ï¼ˆä¸Šæµ·ã®å ´åˆã®ã¿ï¼‰
    if "ä¸Šæµ·" in keyword or "Shanghai" in keyword:
        logger.info(f"ğŸ” KINKAç¤¾ get_kinka_pdf_links.py ã«æ¸¡ã™ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: '{keyword}'")
        pdf_urls_kinka = await get_pdf_links_from_kinka(keyword)
        if not pdf_urls_kinka:
            logger.warning("âš ï¸ KINKAç¤¾ã®PDFãƒªãƒ³ã‚¯å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        else:
            for pdf_url in pdf_urls_kinka:
                result = await extract_schedule_positions(
                    url=pdf_url,
                    departure=departure,
                    destination=destination,
                    etd_date=etd_date,
                    eta_date=eta_date
                )
                if result:
                    result["company"] = "KINKA"
                    result["fare"] = str(get_freight_rate(departure, destination, "KINKA")) if not None else "N/A"
                    results.append(result)
                    logger.info(f"[KINKAç¤¾ãƒãƒƒãƒ] {result}")
                    break
    else:
        logger.info("ğŸ“› KINKAç¤¾ã¯ã€ä¸Šæµ·ã€ã®ã¨ãã®ã¿æ¤œç´¢å¯¾è±¡ã¨ãªã‚‹ãŸã‚ã€ä»Šå›ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚")

    # Evergreenç¤¾ã®å‡¦ç†
    logger.info(f"ğŸ” Evergreenç¤¾ get_pdf_links.py ã«æ¸¡ã™ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: '{keyword}'")
    pdf_urls_shipmentlink = await get_pdf_links_from_shipmentlink(departure, destination)
    
    if not pdf_urls_shipmentlink:
        logger.warning("âš ï¸ Evergreenç¤¾ã®PDFãƒªãƒ³ã‚¯å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    else:
        success = False
        for pdf_url in pdf_urls_shipmentlink:
            result = await extract_schedule_positions(
                url=pdf_url,
                departure=departure,
                destination=destination,
                etd_date=etd_date,
                eta_date=eta_date
            )
            if result:
                result["company"] = "EVERGREEN"
                result["fare"] = str(get_freight_rate(departure, destination, "Shipmentlink")) if not None else "N/A"
                results.append(result)
                logger.info(f"[Evergreenç¤¾ãƒãƒƒãƒ] {result}")
                success = True
                break
        if not success:
            logger.warning("âš ï¸ Evergreenç¤¾ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    # çµæœè¿”å´
    if results:
        logger.info(f"[âœ…MATCHED] {len(results)}ä»¶ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
        return results
    else:
        logger.warning("âŒ å…¨ç¤¾ã®ã„ãšã‚Œã«ã‚‚ãƒãƒƒãƒã—ã¾ã›ã‚“ã§ã—ãŸ")
        return []

@app.post("/update-feedback")
async def update_feedback(data: FeedbackRequest):
    """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ›´æ–°APIï¼ˆç¾è¡Œã®ã¾ã¾ã€ãŸã ã—ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½¿ç”¨ï¼‰"""
    logger.info(f"ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å—ä¿¡: URL={data.url}, ETD={data.etd}, ETA={data.eta}, Feedback={data.feedback}")
    try:
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜
        log_path = os.path.join(OCR_TEMP_FOLDER, "gpt_feedback_log.csv")
        
        file_exists = os.path.exists(log_path)
        with open(log_path, "a", encoding="utf-8", newline='') as f:
            writer = csv.writer(f)
            if not file_exists:
                writer.writerow(["timestamp", "url", "etd", "eta", "feedback"])
            writer.writerow([
                datetime.now().isoformat(),
                data.url,
                data.etd,
                data.eta,
                data.feedback
            ])
        
        return {"message": "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¨˜éŒ²ã—ã¾ã—ãŸã€‚"}
    except Exception as e:
        logger.exception("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¨˜éŒ²ä¸­ã«ã‚¨ãƒ©ãƒ¼")
        raise HTTPException(status_code=500, detail="ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

# ========== ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ï¼ˆOCRæ©Ÿèƒ½å¯¾å¿œç‰ˆï¼‰ ==========
@app.get("/health")
async def health_check():
    """
    Azure App Service ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ç”¨
    ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€OpenAIã€OCRæ©Ÿèƒ½ã€ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¢ã‚¯ã‚»ã‚¹ç¢ºèªä»˜ãï¼‰
    """
    try:
        health_status = {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "services": {}
        }
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç¢ºèª
        try:
            conn = get_db_connection()
            conn.close()
            health_status["services"]["database"] = "connected"
        except Exception as db_error:
            health_status["services"]["database"] = f"error: {str(db_error)}"
        
        # OpenAIæ¥ç¶šç¢ºèª
        try:
            test_response = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": "test"}],
                max_tokens=1
            )
            health_status["services"]["openai"] = "connected"
        except Exception as openai_error:
            health_status["services"]["openai"] = f"error: {str(openai_error)}"
        
        # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ›¸ãè¾¼ã¿æ¨©é™ç¢ºèª
        try:
            temp_test_file = tempfile.NamedTemporaryFile(delete=True, dir=OCR_TEMP_FOLDER)
            temp_test_file.write(b"health check")
            temp_test_file.close()
            health_status["services"]["temp_directory"] = "writable"
        except Exception as temp_error:
            health_status["services"]["temp_directory"] = f"error: {str(temp_error)}"
        
        # Tesseractç¢ºèª
        try:
            import pytesseract
            pytesseract.get_tesseract_version()
            health_status["services"]["tesseract"] = "available"
        except Exception as tesseract_error:
            health_status["services"]["tesseract"] = f"error: {str(tesseract_error)}"
        
        # è¨­å®šæƒ…å ±
        health_status["config"] = {
            "ocr_temp_folder": OCR_TEMP_FOLDER,
            "max_file_size_mb": MAX_FILE_SIZE / (1024 * 1024),
            "allowed_extensions": list(ALLOWED_EXTENSIONS),
            "dev_mode": DEV_MODE
        }
        
        # å…¨ä½“çš„ãªã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¤å®š
        error_services = [k for k, v in health_status["services"].items() if "error" in str(v)]
        if error_services:
            health_status["status"] = "degraded"
            health_status["warning"] = f"ä»¥ä¸‹ã®ã‚µãƒ¼ãƒ“ã‚¹ã«ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Šã¾ã™: {', '.join(error_services)}"
        
        return health_status
        
    except Exception as e:
        return {
            "status": "unhealthy", 
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

# ========== çµ‚äº†æ™‚å‡¦ç†ã®è¿½åŠ  ==========
@app.on_event("shutdown")
async def shutdown_event():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã®å‡¦ç†"""
    logger.info("ğŸ›‘ PO Management System shutting down...")
    
    # çµ‚äº†æ™‚ã«ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    try:
        cleanup_temp_files("*")  # å…¨ã¦ã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        logger.info("ğŸ§¹ çµ‚äº†æ™‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
    except Exception as e:
        logger.warning(f"çµ‚äº†æ™‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

# ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ï¼ˆç¾è¡Œã®ã¾ã¾ï¼‰
@app.middleware("http")
async def catch_exceptions_middleware(request: Request, call_next):
    try:
        return await call_next(request)
    except Exception as e:
        error_trace = traceback.format_exc()
        logger.exception("æœªå‡¦ç†ã®ä¾‹å¤–ãŒç™ºç”Ÿã—ã¾ã—ãŸ:\n%s", error_trace)
        
        return JSONResponse(
            status_code=500,
            content={"detail": error_trace}
        )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=8000,
        reload=DEV_MODE,  # é–‹ç™ºãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã®ã¿reload
        log_level=LOG_LEVEL.lower()
    )